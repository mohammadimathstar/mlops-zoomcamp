{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e6528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/mlops-zoomcamp\n",
      "Current working directory: /workspaces/mlops-zoomcamp/02-experiment tracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the working directory to the location of the notebook\n",
    "notebook_dir = Path(os.getcwd()) / \"02-experiment tracking\"\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1983b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9019968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca833d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    df['PU_DO'] = df.PULocationID + \"_\" + df.DOLocationID\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3410e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594609c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54373 51497\n"
     ]
    }
   ],
   "source": [
    "df_train = read_dataframe('./data/green_tripdata_2024-01.parquet')\n",
    "df_val = read_dataframe('./data/green_tripdata_2024-02.parquet')\n",
    "\n",
    "print(df_train.shape[0], df_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d562f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO', 'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "target = 'duration'\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa165bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root mean squared error is: 5.926355548541141\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(train_dicts, y_train)\n",
    "y_pred = pipeline.predict(val_dicts)\n",
    "\n",
    "print(f\"root mean squared error is: {root_mean_squared_error(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump(pipeline, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c84642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "\n",
    "# mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"mohammad\")\n",
    "\n",
    "    mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2024-01.parquet\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2024-02.parquet\")\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        Lasso(alpha)\n",
    "    )\n",
    "    \n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    pipeline.fit(train_dicts, y_train)\n",
    "\n",
    "    y_pred = pipeline.predict(val_dicts)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"./models/lin_reg.bin\", artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82d9b4",
   "metadata": {},
   "source": [
    "### Adding hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc204ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install hyperopt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# the following uses some 'baysian approach' to find the best hyper-parameter\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv = DictVectorizer()\n",
    "# X_train = dv.fit_transform(train_dicts)\n",
    "# X_val = dv.fit_transform(val_dicts)\n",
    "\n",
    "# train = xgb.DMatrix(X_train, label=y_train)\n",
    "# valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"lasso\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(),\n",
    "            Lasso(alpha=params['alpha'])\n",
    "        )\n",
    "        pipeline.fit(train_dicts, y_train)\n",
    "        y_pred = pipeline.predict(val_dicts)\n",
    "\n",
    "        y_pred = pipeline.predict(val_dicts)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19472db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'alpha': hp.loguniform('alpha', -5, -1),\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79957d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(params):\n",
    "\n",
    "    # Set seeds for reproducibility\n",
    "    seed = params.get('seed', 42)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            # params,\n",
    "            learning_rate=params['learning_rate'],\n",
    "            max_depth=int(params['max_depth']),\n",
    "            reg_alpha=params['reg_alpha'],\n",
    "            reg_lambda=params['reg_lambda'],\n",
    "            random_state=seed,\n",
    "            verbosity=0,\n",
    "            objective=params['objective']\n",
    "        )\n",
    "\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(),\n",
    "            model\n",
    "        )\n",
    "\n",
    "        pipeline.fit(train_dicts, y_train)\n",
    "        y_pred = pipeline.predict(val_dicts)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, -1),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 42\n",
    "}\n",
    "best_result = fmin(\n",
    "    fn=objective_xgb,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "\n",
    "params = {\n",
    "    'learning_rate':    0.410215639489084,\n",
    "    'max_depth':    9,\n",
    "    'min_child_weight':    2.955225015279242,\n",
    "    'objective':     'reg:squarederror',\n",
    "    'reg_alpha':    0.07847140786574915,\n",
    "    'reg_lambda':    0.15098298624710604,\n",
    "    'seed':    42\n",
    "}\n",
    "\n",
    "model = XGBRegressor(\n",
    "    learning_rate=params['learning_rate'],\n",
    "    max_depth=int(params['max_depth']),\n",
    "    reg_alpha=params['reg_alpha'],\n",
    "    reg_lambda=params['reg_lambda'],\n",
    "    random_state=params['seed'],\n",
    "    verbosity=0,\n",
    "    objective=params['objective']\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    model\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    pipeline.fit(train_dicts, y_train)\n",
    "    y_pred = pipeline.predict(val_dicts)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    print(rmse)\n",
    "\n",
    "    mlflow.set_tag(\"model\", \"xgboost\")\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    # Log the entire sklearn pipeline\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b87645",
   "metadata": {},
   "source": [
    "# TO Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b121f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Load the pipeline model\n",
    "model_uri = 'runs:/65a7096112cb41b693e557e8008cfa9c/model'\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict directly on val_dicts (list of dicts)\n",
    "preds = model.predict(val_dicts)\n",
    "\n",
    "print(root_mean_squared_error(y_val, preds))\n",
    "\n",
    "# print(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6189bd",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c50756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# the following uses some 'baysian approach' to find the best hyper-parameter\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gb(params):\n",
    "\n",
    "    # mlflow.sklearn.autolog()\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"gradientboosting\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = GradientBoostingRegressor(\n",
    "            # params,\n",
    "            learning_rate=params['learning_rate'],\n",
    "            max_depth=int(params['max_depth']),\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            random_state=params['random_state'],\n",
    "            verbose=0,\n",
    "            loss=params['loss']\n",
    "        )\n",
    "\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(),\n",
    "            model\n",
    "        )\n",
    "\n",
    "        pipeline.fit(train_dicts, y_train)\n",
    "        y_pred = pipeline.predict(val_dicts)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f99edf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:04:39 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:06:23 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:44<33:06, 104.56s/trial, best loss: 5.383652413454907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:06:23 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:06:45 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:06<16:42, 55.68s/trial, best loss: 5.106544191898413] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:06:45 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:09:03 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [04:23<26:25, 93.24s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:09:03 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:13:19 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [08:40<42:00, 157.52s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:13:19 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:17:00 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [12:20<45:05, 180.38s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:17:00 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:20:57 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [16:18<46:37, 199.85s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:20:57 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:24:45 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [20:06<45:17, 209.06s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:24:46 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:25:49 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [21:10<32:34, 162.88s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:25:49 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:28:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [24:09<30:47, 167.98s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:28:49 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:29:21 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [24:42<21:01, 126.15s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:29:21 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:31:17 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [26:38<18:27, 123.01s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:31:17 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:32:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [28:09<15:06, 113.25s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:32:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:35:31 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [30:52<14:59, 128.51s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:35:32 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:37:28 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [32:49<12:29, 124.88s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:37:28 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:40:44 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [36:05<12:11, 146.26s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:40:44 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:41:28 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [36:49<07:42, 115.63s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:41:28 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:43:03 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [38:23<05:27, 109.24s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:43:03 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:47:09 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [42:30<05:00, 150.49s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:47:09 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:48:10 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [43:30<02:03, 123.46s/trial, best loss: 5.106544191898413]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 16:48:10 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n",
      "2025/05/15 16:51:22 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [46:43<00:00, 140.17s/trial, best loss: 5.106544191898413]\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 4, 50, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, -1),\n",
    "    'loss': 'squared_error',\n",
    "    'random_state': 42\n",
    "}\n",
    "best_result = fmin(\n",
    "    fn=objective_gb,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a821602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.104456270121915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/15 18:25:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'learning_rate':    0.05563655633030401,\n",
    "    \"max_depth\": 13,\n",
    "    \"min_samples_split\": 17,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "model = GradientBoostingRegressor(\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    verbose=0,\n",
    "    loss=best_params['loss']\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    model\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    pipeline.fit(train_dicts, y_train)\n",
    "    y_pred = pipeline.predict(val_dicts)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    print(rmse)\n",
    "\n",
    "    mlflow.set_tag(\"model\", \"gradient_boosting\")\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    # Log the entire sklearn pipeline\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102a82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
